# -*- coding: utf-8 -*-
"""Soft computing.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1fCy0K_PaBTwmGdVhVYR1XkBZPx06dhhL
"""

pip install -U scikit-fuzzy

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt


x = np.arange(0, 11, 1)
mfx = fuzz.trimf(x, [3, 5, 7])


plt.plot(x, mfx, 'b', linewidth=1.5)
plt.title('Triangular membership function')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.ylim([-0.1, 1.1])
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x = np.arange(0, 11, 1)
mfx = fuzz.trapmf(x, [2, 3, 5, 7])

plt.plot(x, mfx, 'b', linewidth=1.5)
plt.title('Trapezoidal membership function')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.ylim([-0.1, 1.1])
plt.show()

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt


x = np.arange(0,11,1)
sigma=1
mean=0


mfx = fuzz.gaussmf(x, 5, 2)


plt.plot(x, mfx, 'b', linewidth=1.5)
plt.title('Gaussian membership function')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.ylim([-0.1, 1.1])
plt.show()

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt
x = np.arange(-5, 5, 0.1)
mfx = fuzz.sigmf(x, 0, 1)
plt.plot(x, mfx, 'b', linewidth=1.5)
plt.title('Sigmoid membership function')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.ylim([-0.1, 1.1])
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x = np.arange(-5, 5, 0.1)
mfx = fuzz.smf(x, 0, 1)
plt.plot(x, mfx, 'b', linewidth=1.5)
plt.title('S-function membership function')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.ylim([-0.1, 1.1])
plt.show()

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_union = np.maximum(mfx1, mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_union, 'k', linewidth=1.5, label='Union of membership functions')
plt.title('Union of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trapmf(x1, [3, 5, 7, 9])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trapmf(x2, [5, 7, 9, 11])
mfx_union = np.maximum(mfx1, mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_union, 'k', linewidth=1.5, label='Union of membership functions')
plt.title('Union of Two Trapezoidal Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_intersection = np.minimum(mfx1, mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_intersection, 'k', linewidth=1.5, label='Intersection of membership functions')
plt.title('Intersection of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_complement = np.minimum(1 - mfx1, 1 - mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_complement, 'k', linewidth=1.5, label='Complement of membership functions')
plt.title('Complement of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_difference = np.maximum(mfx1 - mfx2, 0)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_difference, 'k', linewidth=1.5, label='Difference of membership functions')
plt.title('Difference of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_associative = np.minimum(mfx1, mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_associative, 'k', linewidth=1.5, label='Associative property')
plt.title('Associative Property of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
x3 = np.arange(0, 11, 1)
mfx3 = fuzz.trimf(x3, [7, 9, 11])
mfx_associative = np.minimum(mfx1, np.minimum(mfx2, mfx3))
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x3, mfx3, 'g', linewidth=1.5, label='Membership function 3')
plt.plot(x1, mfx_associative, 'k', linewidth=1.5, label='Associative property')
plt.title('Associative Property of Three Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_distributive1 = np.minimum(mfx1, mfx2)
mfx_distributive2 = np.maximum(mfx1, mfx2) - mfx_distributive1
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_distributive1, 'k', linewidth=1.5, label='Distributive property 1')
plt.plot(x1, mfx_distributive2, 'g', linewidth=1.5, label='Distributive property 2')
plt.title('Distributive Property of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_distributive1 = np.minimum(mfx1, mfx2)
mfx_distributive2 = np.maximum(mfx1, mfx2) - mfx_distributive1
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_distributive1, 'k', linewidth=1.5, label='Distributive property 1')
plt.plot(x1, mfx_distributive2, 'g', linewidth=1.5, label='Distributive property 2')
plt.title('Distributive Property of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_commutative1 = np.minimum(mfx1, mfx2)
mfx_commutative2 = np.minimum(mfx2, mfx1)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_commutative1, 'k', linewidth=1.5, label='Commutative property 1')
plt.plot(x1, mfx_commutative2, 'g', linewidth=1.5, label='Commutative property 2')
plt.title('Commutative Property of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

import matplotlib.pyplot as plt
import numpy as np
x1 = np.arange(0, 11, 1)
mfx1 = fuzz.trimf(x1, [3, 5, 7])
x2 = np.arange(0, 11, 1)
mfx2 = fuzz.trimf(x2, [5, 7, 9])
mfx_de_morgan1 = np.maximum(1 - mfx1, 1 - mfx2)
mfx_de_morgan2 = 1 - np.minimum(mfx1, mfx2)
plt.plot(x1, mfx1, 'b', linewidth=1.5, label='Membership function 1')
plt.plot(x2, mfx2, 'r', linewidth=1.5, label='Membership function 2')
plt.plot(x1, mfx_de_morgan1, 'k', linewidth=1.5, label='De morgan property 1')
plt.plot(x1, mfx_de_morgan2, 'g', linewidth=1.5, label='De morgan property 2')
plt.title('De Morgan Property of Two Triangular Membership Functions')
plt.ylabel('Membership degree')
plt.xlabel('Value')
plt.grid(True)
plt.legend()
plt.show()

"""DAY-2"""

import numpy as np
import skfuzzy as fuzz
from skfuzzy import control as ctrl
quality = ctrl.Antecedent(np.arange(0, 11, 1), 'quality')
service = ctrl.Antecedent(np.arange(0, 11, 1), 'service')
tip = ctrl.Consequent(np.arange(0, 26, 1), 'tip')
quality.automf(3)
service.automf(3)
tip['low'] = fuzz.trimf(tip.universe, [0, 0, 13])
tip['medium'] = fuzz.trimf(tip.universe, [0, 13, 25])
tip['high'] = fuzz.trimf(tip.universe, [13, 25, 25])
rule1 = ctrl.Rule(quality['poor'] & service['poor'], tip['low'])
rule2 = ctrl.Rule(quality['average'] & service['poor'], tip['low'])
rule3 = ctrl.Rule(quality['good'] & service['poor'], tip['medium'])
rule4 = ctrl.Rule(quality['poor'] & service['average'], tip['low'])
rule5 = ctrl.Rule(quality['average'] & service['average'], tip['medium'])
rule6 = ctrl.Rule(quality['good'] & service['average'], tip['high'])
rule7 = ctrl.Rule(quality['poor'] & service['good'], tip['medium'])
rule8 = ctrl.Rule(quality['average'] & service['good'], tip['high'])
rule9 = ctrl.Rule(quality['good'] & service['good'], tip['high'])
tipping_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])
tipping = ctrl.ControlSystemSimulation(tipping_ctrl)
tipping.input['quality'] = 6
tipping.input['service'] = 9
tipping.compute()
print(tipping.output['tip'])
tip.view(sim=tipping)

"""DAY-3"""

import numpy as np
def activation(x):
  if x > 0:
    return 1
  else:
    return 0
w1 = 1
w2 = 1
b = -1
x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 0, 0, 1])
for i in range(len(x)):
  weighted_sum = w1 * x[i][0] + w2 * x[i][1] + b
  output = activation(weighted_sum)
  print("Input:", x[i], "Weighted sum:", weighted_sum, "Output:", output)
  if output == y[i]:
    print("Correct")
  else:
    print("Incorrect")

import numpy as np
def activation(x):
  if x > 0:
    return 1
  else:
    return 0
w1 = 1
w2 = 1
b = -0.5
x = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
y = np.array([0, 1, 1, 1])
for i in range(len(x)):
  weighted_sum = w1 * x[i][0] + w2 * x[i][1] + b
  output = activation(weighted_sum)
  print("Input:", x[i], "Weighted sum:", weighted_sum, "Output:", output)
  if output == y[i]:
    print("Correct")
  else:
    print("Incorrect")

"""DAY-4"""

import numpy as np
import matplotlib.pyplot as plt

def activation(x):
  if x > 0:
    return 1
  elif x < 0:
    return -1
  else:
    return 0

def train_perceptron(x, y, epochs):
  w1 = 0
  w2 = 0
  b = 0
  for i in range(epochs):
    for j in range(4):
      net = w1 * x[j][0] + w2 * x[j][1] + b
      output = activation(net)
      error = y[j] - output
      w1 += error * x[j][0]
      w2 += error * x[j][1]
      b += error
  return w1, w2, b

x = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
y = np.array([[-1], [-1], [-1], [1]])
epochs = 3
w1, w2, b = train_perceptron(x, y, epochs)
print("Weights: w1 = {}, w2 = {}".format(w1, w2))
print("Bias: b = {}".format(b))

# prompt: print graph for the last above code

import numpy as np
import matplotlib.pyplot as plt

x1 = np.array([-1, -1, 1, 1])
x2 = np.array([-1, 1, -1, 1])
y = np.array([-1, -1, -1, 1])

# Plot the data points
plt.scatter(x1, x2, c=y, cmap='viridis')

# Create the decision boundary
x_min, x_max = plt.xlim()
y_min, y_max = plt.ylim()

# Define the equation of the line
m = -(w1 / w2)
b = -(b / w2)

# Plot the line
x = np.linspace(x_min, x_max)
y = m * x + b

plt.plot(x, y, '-r')

# Show the plot
plt.show()

"""DAY-5"""

import numpy as np
import matplotlib.pyplot as plt

X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])

t = np.array([-1, -1, -1, 1])

w = np.array([0.1, 0.1])
b = 1

learning_rate = 0.1

iterations = 10

for i in range(iterations):
    for j in range(len(X)):

        output = np.dot(X[j], w) + b

        error = t[j] - output

        w += learning_rate * error * X[j]
        print(w)

print("Final weights:", w)
output = np.dot(X, w) + b
print("Output:", output)

import matplotlib.pyplot as plt
import numpy as np

X = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])

t = np.array([-1, 1, 1, -1])

w = np.array([0.1, 0.1])
b = 1

learning_rate = 0.1

iterations = 10

for i in range(iterations):
    for j in range(len(X)):

        output = np.dot(X[j], w) + b

        error = t[j] - output

        w += learning_rate * error * X[j]
        print(w)

print("Final weights:", w)
output = np.dot(X, w) + b
print("Output:", output)

"""DAY-6"""

# prompt: implementation of composition of fuzzy and crisp relations

import numpy as np

# Define the fuzzy relation R
R = np.array([[0.5, 0.7],
              [0.3, 0.8]])

# Define the crisp relation S
S = np.array([[1, 0],
              [0, 1]])

# Calculate the composition of R and S
composition = np.dot(R, S)

# Print the composition
print(composition)

import numpy as np

# Define the Madaline class
class Madaline:
    def __init__(self, input_size, hidden_size, learning_rate=0.1, epochs=100):
        self.input_size = input_size
        self.hidden_size = hidden_size
        self.learning_rate = learning_rate
        self.epochs = epochs
        # Initialize weights randomly for input layer
        self.weights_input = np.random.randn(input_size + 1, hidden_size)
        # Initialize weights randomly for hidden layer
        self.weights_hidden = np.random.randn(hidden_size + 1)

    def activation(self, x):
        return 1 if x >= 0 else -1  # Bipolar activation function

    def predict(self, inputs):
        # Forward pass through input layer
        input_activation = np.dot(inputs, self.weights_input[1:, :]) + self.weights_input[0, :]
        input_output = np.where(input_activation >= 0, 1, -1)
        # Forward pass through hidden layer
        hidden_input = np.dot(input_output, self.weights_hidden[1:]) + self.weights_hidden[0]
        return self.activation(hidden_input)

    def train(self, training_inputs, labels):
        for _ in range(self.epochs):
            for inputs, label in zip(training_inputs, labels):
                # Forward pass
                input_activation = np.dot(inputs, self.weights_input[1:, :]) + self.weights_input[0, :]
                input_output = np.where(input_activation >= 0, 1, -1)
                hidden_input = np.dot(input_output, self.weights_hidden[1:]) + self.weights_hidden[0]
                prediction = self.activation(hidden_input)
                # Backpropagation
                output_error = label - prediction
                hidden_error = output_error * self.weights_hidden[1:]
                # Update weights for hidden layer
                self.weights_hidden[1:] += self.learning_rate * output_error * input_output
                self.weights_hidden[0] += self.learning_rate * output_error
                # Update weights for input layer
                self.weights_input[1:, :] += self.learning_rate * hidden_error * inputs[:, np.newaxis]
                self.weights_input[0, :] += self.learning_rate * hidden_error

# XOR function with bipolar inputs and target
training_inputs = np.array([[-1, -1], [-1, 1], [1, -1], [1, 1]])
labels = np.array([-1, 1, 1, -1])  # XOR truth table

# Create and train Madaline network
madaline = Madaline(input_size=2, hidden_size=2)
madaline.train(training_inputs, labels)

# Test the trained model
test_inputs = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])
for inputs in test_inputs:
    prediction = madaline.predict(inputs)
    print(f"Input: {inputs},\tPredicted Output: {prediction}")

"""DAY-7"""

import numpy as np

def generate_random_binary_input(length):
  return np.random.randint(low=0, high=2, size=length)

inputs = []

for _ in range(4):
  inputs.append(generate_random_binary_input(5))

for input in inputs:
  print(input)

def fitness(input):
  decimal_input = int(''.join(map(str, input)), 2)
  output = decimal_input ** 2
  return output

for input in inputs:
  fitness_value = fitness(input)
  print(f"Input: {input}, Fitness: {fitness_value}")

def selection(population, fitness_values):
  fitness_individuals = list(zip(fitness_values, population))
  fitness_individuals.sort(key=lambda x: x[0], reverse=True)
  selected_individuals = [individual for _, individual in fitness_individuals]

  return selected_individuals

def crossover(selected_individuals, crossover_rate):
  offspring = []

  for i in range(0, len(selected_individuals), 2):
    random_number = np.random.rand()

    if random_number < crossover_rate:
      parent1 = selected_individuals[i]
      parent2 = selected_individuals[i + 1]
      crossover_point = np.random.randint(1, len(parent1) - 1)
      offspring1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))
      offspring2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))
      offspring.append(offspring1)
      offspring.append(offspring2)

  return offspring

def mutation(offspring, mutation_rate):

  for individual in offspring:

    for i in range(len(individual)):
      random_number = np.random.rand()

      if random_number < mutation_rate:
        individual[i] = 1 - individual[i]

  return offspring

def new_population(population, offspring):
  population = offspring

  return population

population = [generate_random_binary_input(5) for _ in range(10)]
generations = 10
crossover_rate = 0.8
mutation_rate = 0.1

for generation in range(generations):
    fitness_values = [fitness(individual) for individual in population]
    selected_individuals = selection(population, fitness_values)
    offspring = crossover(selected_individuals, crossover_rate)
    offspring = mutation(offspring, mutation_rate)

    if offspring:
        population = new_population(population, offspring)
        best_fitness = max(fitness_values)
        print(f"Generation {generation + 1}: Best Fitness = {best_fitness}")
    else:
        print(f"Generation {generation + 1}: No offspring produced. Continuing with the current population.")

fitness_values = [fitness(individual) for individual in population]
best_individual = population[np.argmax(fitness_values)]
print(f"Best Individual: {best_individual}, Fitness: {fitness(best_individual)}")

x

!pip install geneticalgorithm
from geneticalgorithm import geneticalgorithm as ga
import numpy as np

# Define the objective function to be optimized
def objective_function(x):
    return np.sum(x**2)

# Define the bounds for the variables
varbound = np.array([[0, 10]]*5)  # Assuming 5 variables with bounds [0, 10]

# Create an instance of the GeneticAlgorithm class
model = ga(function=objective_function, dimension=5, variable_type='real', variable_boundaries=varbound)

# Run the optimization
model.run()
7
# Print the results
print("Best solution found:", model.output_dict['variable'])
print("Objective value at best solution:", model.output_dict['function'])

import random

# Define parameters
POPULATION = [12, 25, 5, 19]  # Initial population
MUTATION_RATE = 0.1

# Define fitness function
def fitness_function(x):
    return x**2

# Perform crossover
def crossover(parent1, parent2):
    crossover_point = random.randint(1, 4)  # Choose crossover point
    child1 = (parent1 >> crossover_point << crossover_point) + (parent2 & ((1 << crossover_point) - 1))
    child2 = (parent2 >> crossover_point << crossover_point) + (parent1 & ((1 << crossover_point) - 1))
    return child1, child2, crossover_point

# Perform mutation
def mutation(individual):
    mutated_individual = individual
    for i in range(5):  # Considering each bit position
        if random.random() < MUTATION_RATE:
            mutated_individual = mutated_individual ^ (1 << i)  # Flip the bit
    return mutated_individual

# Main genetic algorithm function for single generation
def single_generation():
    population = POPULATION
    print("Table 1: Initial Population")
    print("String No. | Initial Population | X Value | Fitness (f(x) = x^2) | Prob | % Prob | Expected Count | Actual Count")
    expected_counts = [fitness_function(individual) for individual in population]  # Expected count for each individual
    for idx, ind in enumerate(population):
        prob = expected_counts[idx] / sum(expected_counts)
        percentage_prob = prob * 100
        actual_count = population.count(ind)
        print(f"{idx + 1:9} | {ind:19b} | {ind:7} | {fitness_function(ind):18} | {prob:.4f} | {percentage_prob:.2f}% | {expected_counts[idx]:13.4f} | {actual_count:12}")

    print("\nTable 2: Offspring after Crossover")
    print("String No. | Mating Pool | Crossover Point | Offspring after crossover | X Value | Fitness (f(x) = x^2)")
    for j in range(len(population) // 2):
        parent1, parent2 = random.sample(population, 2)  # Select two random parents
        child1, child2, crossover_point = crossover(parent1, parent2)
        child1 = mutation(child1)
        child2 = mutation(child2)
        print(f"{j + 1:9} | {parent1:11}, {parent2:2} | {crossover_point:15} | {child1:25}, {child2:2} | {child1:7}, {child2:2} | {fitness_function(child1):20}, {fitness_function(child2):2}")

# Run the genetic algorithm for single generation
single_generation()