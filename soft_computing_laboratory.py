# -*- coding: utf-8 -*-
"""Soft Computing Laboratory.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VFZ9CygP4ibNKY70U4-8WL3_9TTvsY_u

# ***Day - 1 : Implement the Max-Min Composition and Max-Product Composition***
"""

import numpy as np

def calculate_fuzzy_matrix(elements, membership_function):
    matrix_size = len(elements)
    fuzzy_matrix = np.zeros((matrix_size, matrix_size))

    for i in range(matrix_size):
        for j in range(matrix_size):
            fuzzy_matrix[i, j] = membership_function(elements[i], elements[j])

    return fuzzy_matrix

# Example membership function - you can replace this with your specific function
def triangular_membership(x, y):
    return max(0, 1 - abs(x - y)/2)

# Example usage:
elements = [1, 2, 3, 4, 5]

fuzzy_matrix = calculate_fuzzy_matrix(elements, triangular_membership)

print("Fuzzy Matrix:")
print(fuzzy_matrix)

"""***Max-Product***"""

import numpy as np
def maxMin(x,y):
    z=[]
    for x1 in x:
        for y1 in y.T:
            z.append(max(np.minimum(x1,y1)))
    return np.array(z).reshape((x.shape[0],y.shape[1]))

def maxProduct(x,y):
    z = []
    for x1 in x:
        for y1 in y.T:
            z.append(max(np.multiply(x1, y1)))
    return np.array(z).reshape((x.shape[0], y.shape[1]))

r1=np.array([[1,0,.7],[3,.2,0],[0,.5,1]])
r2=np.array([[.6,.6,0],[0,.6,.1],[0,.1,0]])
r3=np.array([[1,0,.7],[0,1,0],[.7,0,1]])


print ("R1oR2 => Max-Min :\n" + str(maxMin(r1, r2)) + "\n")
print ("R1oR2 => Max-Product :\n" + str(maxProduct(r1, r2)) + "\n\n")

print ("R1oR3 => Max-Min :\n" + str(maxMin(r1, r3)) + "\n")
print ("R1oR3 => Max-Product :\n" + str(maxProduct(r1, r3)) + "\n\n")

print ("R1oR2oR3 => Max-Min :\n" + str(maxMin(r1, maxMin(r2, r3))) + "\n")
print ("R1oR2oR3 => Max-Product :\n" + str(maxProduct(r1, maxProduct(r2, r3))) + "\n\n")

"""***Max-Min Composition***"""

import numpy as np

def max_min_composition(matrix1, matrix2):
    rows1, cols1 = matrix1.shape
    rows2, cols2 = matrix2.shape

    if cols1 != rows2:
        raise ValueError("Number of columns in the first matrix must be equal to the number of rows in the second matrix.")

    result_matrix = np.zeros((rows1, cols2))

    for i in range(rows1):
        for j in range(cols2):
            max_min_value = max(min(matrix1[i, k], matrix2[k, j]) for k in range(cols1))
            result_matrix[i, j] = max_min_value

    return result_matrix

# Example usage:
matrix_R = np.array([[0.4, 0.2],
                    [0.2, 0.5]])

matrix_S = np.array([[0.5, 0.3],
                    [0.4, 0.2]])

result_composition = max_min_composition(matrix_R, matrix_S)

print("Matrix R:")
print(matrix_R)
print("\nMatrix S:")
print(matrix_S)
print("\nMax-Min Composition:")
print(result_composition)

import numpy as np

def max_product(matrix1, matrix2):
    rows1, cols1 = matrix1.shape
    rows2, cols2 = matrix2.shape

    if cols1 != rows2:
        raise ValueError("Number of columns in the first matrix must be equal to the number of rows in the second matrix.")

    result_matrix = np.zeros((rows1, cols2))

    for i in range(rows1):
        for j in range(cols2):
            max_product_value = max(matrix1[i, k] * matrix2[k, j] for k in range(cols1))
            result_matrix[i, j] = max_product_value

    return result_matrix

# Example usage:
matrix_A = np.array([[0.8, 0.4],
                    [0.2, 0.6]])

matrix_B = np.array([[0.5, 0.3],
                    [0.7, 0.9]])

result_max_product = max_product(matrix_A, matrix_B)

print("Matrix A:")
print(matrix_A)
print("\nMatrix B:")
print(matrix_B)
print("\nMax Product:")
print(result_max_product)



"""# ***Day - 2 : Implement Fuzzy Membership Functions, Operations and Properties.***"""

!pip install scikit-fuzzy

"""***Triangular Function***"""

import numpy as np
import skfuzzy as fuzz
from matplotlib import pyplot as plt

x = np.arange(11)
x

mfx = fuzz.trimf(x, [0, 5, 10])
mfx

plt.title("TRIANGULAR PLOT")
plt.plot(x, mfx)

plt.show()

"""***Trapezodial Function***"""

start = 0
stop = 10 + 0.001
step = 0.25
x = np.arange(start, stop, step)
x

trimf = fuzz.trimf(x, [0, 5, 10])
trapmf = fuzz.trapmf(x, [0, 2, 8, 10])

plt.title("TRAPEZOIDAL PLOT")
# plt.plot(x, trimf, label="X")
plt.plot(x, trapmf, label="Y")
plt.legend(loc="upper right")
plt.show()

"""***S-Function***"""

start = 0
stop = 10 + 0.001
step = 0.25
x = np.arange(start, stop, step)
x

foot = 1.0
ceiling = 9.0
smf = fuzz.smf(x, foot, ceiling)

plt.plot(x, smf, label="S-function")
plt.legend(loc="upper right")
plt.savefig("function.png")
plt.show()

"""***Sigmoid Function***"""

start = 0
stop = 10 + 0.001
step = 0.25
x = np.arange(start, stop, step)
x

center = 5.0
width_control = 2.0
sigmf = fuzz.sigmf(x, center, width_control)

plt.plot(x, sigmf, label="Sigmoid")
plt.legend(loc="upper right")
plt.savefig("function.png")
plt.show()

"""***Gaussian Function***"""

start = 0
stop = 10 + 0.001
step = 0.25
x = np.arange(start, stop, step)
x

# Gaussian function
mean = 5.0
sigma = 1.25
gaussmf = fuzz.gaussmf(x, mean, sigma)

plt.plot(x, gaussmf, label="Gaussan")

plt.legend(loc="upper right")
plt.savefig("memship-function.png")
plt.show()

"""***Operations:***

1. Union
2. Intersection
3. Complement
4. Bounded difference
5. Bounded product
6. Algebric sum
"""

# Define universe and membership functions
x = np.arange(0, 11, 1)
A = fuzz.trimf(x, [2, 5, 8])
B = fuzz.trimf(x, [0, 3, 6])

# 1. Union
union = np.fmax(A, B)

plt.plot(x, A, label='A')
plt.plot(x, B, label='B')
plt.plot(x, union, label='A ∪ B', linestyle='--')
plt.title('Sets A, B, and Their Union')
plt.legend()

# 2. Intersection
intersection = np.fmin(A, B)

plt.plot(x, A, label='A')
plt.plot(x, B, label='B')
plt.plot(x, intersection, label='A ∩ B', linestyle=':')
plt.title('Sets A, B, and Their Intersection')
plt.legend()

# 3. Complement
complement_A = 1 - A
complement_B = 1 - B

plt.plot(x, A, label='A')
plt.plot(x, complement_A, label='A\'')
plt.title('Complements of Sets A and B')
plt.legend()

# 4. Bounded difference
bounded_difference = np.fmax(A - B, 0)

plt.plot(x, A, label='A')
plt.plot(x, B, label='B')
plt.plot(x, bounded_difference, label='Bounded Difference (A ⊖ B)')
plt.title('Bounded Difference between Sets A and B')
plt.xlabel('x')
plt.ylabel('Membership')
plt.legend()

# 5. Bounded product
bounded_product = np.fmin(A, B)

plt.plot(x, A, label='A')
plt.plot(x, B, label='B')
plt.plot(x, bounded_product, label='Bounded Product (A ⊗ B)', linestyle='--')
plt.title('Sets A, B, and Their Bounded Product')
plt.xlabel('x')
plt.ylabel('Membership')
plt.legend()

# 6. Algebraic sum
algebraic_sum = A + B - A * B

plt.plot(x, A, label='A')
plt.plot(x, B, label='B')
plt.plot(x, algebraic_sum, label='Algebraic Sum (A ⊕ B)', linestyle='--')
plt.title('Sets A, B, and Their Algebraic Sum')
plt.xlabel('x')
plt.ylabel('Membership')
plt.legend()

"""# ***Day - 3 : Implement a Fuzzy Inference System***"""

!pip install scikit-fuzzy

# prompt: Implement a fuzzy inference system

import numpy as np
from skfuzzy import control as ctrl

# Define the input and output variables
distance = ctrl.Antecedent(np.arange(0, 11, 1), 'distance')
speed = ctrl.Antecedent(np.arange(0, 11, 1), 'speed')
acceleration = ctrl.Consequent(np.arange(0, 11, 1), 'acceleration')

# Define the membership functions for each variable
distance['close'] = fuzz.trapmf(distance.universe, [0, 0, 3, 5])
distance['medium'] = fuzz.trimf(distance.universe, [3, 5, 7])
distance['far'] = fuzz.trapmf(distance.universe, [5, 7, 10, 10])

speed['slow'] = fuzz.trapmf(speed.universe, [0, 0, 3, 5])
speed['medium'] = fuzz.trimf(speed.universe, [3, 5, 7])
speed['fast'] = fuzz.trapmf(speed.universe, [5, 7, 10, 10])

acceleration['low'] = fuzz.trapmf(acceleration.universe, [0, 0, 3, 5])
acceleration['medium'] = fuzz.trimf(acceleration.universe, [3, 5, 7])
acceleration['high'] = fuzz.trapmf(acceleration.universe, [5, 7, 10, 10])

# Define the fuzzy rules
rule1 = ctrl.Rule(distance['close'] & speed['slow'], acceleration['low'])
rule2 = ctrl.Rule(distance['close'] & speed['medium'], acceleration['medium'])
rule3 = ctrl.Rule(distance['close'] & speed['fast'], acceleration['high'])
rule4 = ctrl.Rule(distance['medium'] & speed['slow'], acceleration['low'])
rule5 = ctrl.Rule(distance['medium'] & speed['medium'], acceleration['medium'])
rule6 = ctrl.Rule(distance['medium'] & speed['fast'], acceleration['high'])
rule7 = ctrl.Rule(distance['far'] & speed['slow'], acceleration['low'])
rule8 = ctrl.Rule(distance['far'] & speed['medium'], acceleration['medium'])
rule9 = ctrl.Rule(distance['far'] & speed['fast'], acceleration['high'])

# Create the fuzzy inference system
acceleration_ctrl = ctrl.ControlSystem([rule1, rule2, rule3, rule4, rule5, rule6, rule7, rule8, rule9])
acceleration_simulation = ctrl.ControlSystemSimulation(acceleration_ctrl)

# Set the input values
distance_input = 5
speed_input = 7

# Simulate the system
acceleration_simulation.input['distance'] = distance_input
acceleration_simulation.input['speed'] = speed_input
acceleration_simulation.compute()

# Print the output
print(acceleration_simulation.output['acceleration'])

# prompt: IMPLEMENT FUZZY INFERENCE SYSYEM

import numpy as np
import skfuzzy as fuzz
from skfuzzy import control as ctrl

# Define the input and output variables
universe = np.linspace(0, 100, 101)
quality = ctrl.Antecedent(universe, 'quality')
service = ctrl.Antecedent(universe, 'service')
tip = ctrl.Consequent(universe, 'tip')

# Define the membership functions for each variable
quality.automf(3, names=['bad', 'average', 'good'])
service.automf(3, names=['bad', 'average', 'good'])
tip.automf(3, names=['low', 'medium', 'high'])

# Define the fuzzy rules
rule1 = ctrl.Rule(quality['bad'] | service['bad'], tip['low'])
rule2 = ctrl.Rule(quality['average'], tip['medium'])
rule3 = ctrl.Rule(quality['good'] | service['good'], tip['high'])

# Create the fuzzy inference system
tipping_ctrl = ctrl.ControlSystem([rule1, rule2, rule3])
tipping = ctrl.ControlSystemSimulation(tipping_ctrl)

# Pass input values to the system
tipping.input['quality'] = 60
tipping.input['service'] = 80

# Crunch the numbers
tipping.compute()

# Print the output
print(tipping.output['tip'])

# Plot the output membership function
tip.view(sim=tipping)

import numpy as np
import matplotlib.pyplot as plt

# Define triangular membership functions
def triangular_mf(x, a, b, c):
    return np.maximum(0, np.minimum((x - a) / (b - a), (c - x) / (c - b)))

# Define distances
distances = {
    "Very near": (0, 1, 2),
    "Near": (1, 3, 5),
    "Far": (3, 6, 9),
    "Very far": (6, 10, 15)
}

# Generate x values
x = np.linspace(0, 15, 100)

# Plot membership functions
plt.figure(figsize=(10, 6))
for distance, params in distances.items():
    plt.plot(x, triangular_mf(x, *params), label=distance)

plt.title('Triangular Membership Functions for Distances')
plt.xlabel('Distance')
plt.ylabel('Membership Degree')
plt.legend()
plt.grid(True)
plt.show()

import numpy as np
import skfuzzy as fuzz
import matplotlib.pyplot as plt

# Define input variable range
distance = np.arange(0.1, 2.2, 0.1)

# Define membership functions
very_far = fuzz.trimf(distance, [1.5, 2.2, 2.2])
far = fuzz.trimf(distance, [0.8, 1.5, 2.2])
near = fuzz.trimf(distance, [0.1, 0.8, 1.5])
very_near = fuzz.trimf(distance, [0.1, 0.1, 0.8])

# Visualize membership functions
plt.figure()

plt.plot(distance, very_far, 'r', label='Very Far')
plt.plot(distance, far, 'g', label='Far')
plt.plot(distance, near, 'b', label='Near')
plt.plot(distance, very_near, 'm', label='Very Near')

plt.title('Membership Functions for Distance')
plt.ylabel('Membership')
plt.xlabel('Distance (units)')
plt.legend()
plt.grid()

# Take input from user
input_distance = float(input("Enter the distance value: "))

# Calculate membership degrees
membership_very_near = fuzz.interp_membership(distance, very_near, input_distance)
membership_near = fuzz.interp_membership(distance, near, input_distance)
membership_far = fuzz.interp_membership(distance, far, input_distance)
membership_very_far = fuzz.interp_membership(distance, very_far, input_distance)

print("Membership degree for Very Near:", membership_very_near)
print("Membership degree for Near:", membership_near)
print("Membership degree for Far:", membership_far)
print("Membership degree for Very Far:", membership_very_far)

# Highlight input value on the plot
plt.axvline(x=input_distance, color='k', linestyle='--')
plt.text(input_distance + 1, 0.5, f'Input Distance: {input_distance}', rotation=90)

plt.show()

nr = 0.6571
fr = 0.3428
a = 0.3333
ar = 0.6667

alpha_1 = min(nr,a)
print(alpha_1)

alpha_2 = min(nr, ar)
print(alpha_2)

alpha_3 = min(ar, a)
print(alpha_3)

alpha_4 = min(fr, ar)
print(alpha_4)



"""# ***Day - 4 : Implement AND and OR Gate using M-P Neural Model***"""

class MPNeuron:
    def __init__(self, threshold):
        self.threshold = threshold

    def predict(self, inputs):
        if sum(inputs) >= self.threshold:
            return 1
        else:
            return 0

# Define the thresholds for the AND and OR gates
threshold_and = 2
threshold_or = 1

# Create instances of the MP neuron with the respective thresholds
and_gate = MPNeuron(threshold_and)
or_gate = MPNeuron(threshold_or)

# Take user input for the values of the two wires
input1 = int(input("Enter value for wire 1 (0 or 1): "))
input2 = int(input("Enter value for wire 2 (0 or 1): "))

# Compute outputs for AND and OR gates
output_and = and_gate.predict((input1, input2))
output_or = or_gate.predict((input1, input2))

# Print the outputs
print("AND Gate Output:", output_and)
print("OR Gate Output:", output_or)



"""# ***Day - 5 : Implement AND and OR Gate using Perceptron***

"""

import numpy as np

class Perceptron:
    def __init__(self, num_inputs, learning_rate=0.1, epochs=100):
        self.num_inputs = num_inputs
        self.learning_rate = learning_rate
        self.epochs = epochs
        self.weights = np.random.rand(num_inputs + 1)  # Additional weight for bias

    def activation(self, x):
        return 1 if x >= 0 else 0

    def predict(self, inputs):
        summation = np.dot(inputs, self.weights[1:]) + self.weights[0]  # Add bias
        return self.activation(summation)

    def train(self, training_inputs, labels):
        for _ in range(self.epochs):
            for inputs, label in zip(training_inputs, labels):
                prediction = self.predict(inputs)
                self.weights[1:] += self.learning_rate * (label - prediction) * inputs
                self.weights[0] += self.learning_rate * (label - prediction)  # Update bias

def main():
    # Training data for AND gate
    training_inputs_and = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    labels_and = np.array([0, 0, 0, 1])

    # Training data for OR gate
    training_inputs_or = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])
    labels_or = np.array([0, 1, 1, 1])

    # Create Perceptron instances for AND and OR gates
    perceptron_and = Perceptron(2)
    perceptron_or = Perceptron(2)

    # Train Perceptrons
    perceptron_and.train(training_inputs_and, labels_and)
    perceptron_or.train(training_inputs_or, labels_or)

    #Taking Inputs
    x1 = int(input("Enter input x1 (0 or 1): "))
    x2 = int(input("Enter input x2 (0 or 1): "))

    # Testing AND and OR gate
    inputs_and = np.array([x1, x2])
    prediction_and = perceptron_and.predict(inputs_and)
    print(f"AND gate result: {inputs_and} -> {prediction_and}")

    # Test OR gate
    inputs_or = np.array([x1, x2])
    prediction_or = perceptron_or.predict(inputs_or)
    print(f"OR gate result: {inputs_or} -> {prediction_or}")

if __name__ == "__main__":
    main()



"""# ***Day - 6 : Implement AND and OR Gate using Adaline***

"""

import numpy as np

# The features for the OR model, here we have taken the possible values for combination of two inputs
features = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])

# Labels for the OR model, here the output for the features is taken as an array
labels = np.array([1, 1, 1, -1])

# Initialise weights, bias, learning rate, epoch
weight = np.array([0.1, 0.1])
bias = 0.1
learning_rate = 0.2
epoch = 10

for i in range(epoch):
	# Epoch is the number of times the model is trained with the same data
	print("Epoch:", i+1)

	# Variable to check if there is no change in previous weight and present calculated weight
	# Initial error is kept as 0
	sum_squared_error = 0.0

	# For each of the possible input given in the features
	for j in range(len(features)):
		# Actual output to be obtained
		actual = labels[j]

		# The value of two features as given in the features array
		x1, x2 = features[j]

		# Net unit value computation performed to obtain the sum of features multiplied with their weights
		unit = np.dot(np.array([x1, x2]), weight) + bias

		# Error is computed so as to update the weights
		error = actual - unit

		# Print statement to print the actual value, predicted value and the error
		print("Error =", error)

		# Summation of squared error is calculated
		sum_squared_error += error ** 2

		# Updation of weights, summing up of product of learning rate, sum of squared error and feature value
		weight[0] += learning_rate * error * x1
		weight[1] += learning_rate * error * x2

		# Updation of bias, summing up of product of learning rate and sum of squared error
		bias += learning_rate * error

	print("Sum of squared error =", sum_squared_error / len(features), "\n")

"""# ***Day - 7 :Implementation of XOR functions with bipolar inputs & target using Madaline network.***"""

import numpy as np

class Madaline:
    def __init__(self, num_inputs, num_outputs, learning_rate=0.1, threshold=0):
        self.num_inputs = num_inputs
        self.num_outputs = num_outputs
        self.learning_rate = learning_rate
        self.threshold = threshold
        self.weights = np.random.rand(num_inputs + 1, num_outputs) * 2 - 1  # Additional weight for bias

    def activation(self, x):
        return 1 if x >= self.threshold else -1

    def predict(self, inputs):
        summation = np.dot(np.append(inputs, 1), self.weights)  # Add bias
        return np.array([self.activation(s) for s in summation])

    def train(self, training_inputs, labels, max_epochs=1000):
        for epoch in range(max_epochs):
            errors = 0
            for inputs, label in zip(training_inputs, labels):
                prediction = self.predict(inputs)
                if not np.array_equal(prediction, label):
                    errors += 1
                    self.update_weights(inputs, label)
            if errors == 0:
                print(f"Converged after {epoch + 1} epochs.")
                break

    def update_weights(self, inputs, label):
        prediction = self.predict(inputs)
        for i in range(self.num_inputs):
            for j in range(self.num_outputs):
                self.weights[i][j] += self.learning_rate * (label[j] - prediction[j]) * inputs[i]
        for j in range(self.num_outputs):
            self.weights[self.num_inputs][j] += self.learning_rate * (label[j] - prediction[j])  # Update bias


# Training data for XOR with bipolar inputs and targets
training_inputs = np.array([[1, 1], [1, -1], [-1, 1], [-1, -1]])
labels = np.array([[1, -1], [-1, 1], [-1, 1], [1, -1]])  # Target outputs

# Create Madaline instance
madaline = Madaline(num_inputs=2, num_outputs=2, learning_rate=0.1, threshold=0)

# Train the Madaline network
madaline.train(training_inputs, labels)

# Test the trained network
for inputs in training_inputs:
    prediction = madaline.predict(inputs)
    print(f"Input: {inputs}, Prediction: {prediction}")

"""# ***Day - 8 :Implementation of maximizing 𝐹(𝑥)=𝑥2 , where x ranges from say 0 to 31 using Genetic Algorithm.***"""

# prompt: Implementation of maximizing 𝐹(𝑥)=𝑥2 , where x ranges from say 0 to 31 using Genetic Algorithm.

import random
import math
import numpy as np

def fitness_function(x):
    return x**2

def generate_population(pop_size):
    population = []
    for _ in range(pop_size):
        x = random.randint(0, 31)
        population.append(x)
    return population

def crossover(parent1, parent2):
    crossover_point = random.randint(1, len(parent1) - 1)
    child1 = parent1[:crossover_point] + parent2[crossover_point:]
    child2 = parent2[:crossover_point] + parent1[crossover_point:]
    return child1, child2

def mutate(individual):
    mutation_rate = 0.01
    for i in range(len(individual)):
        if random.random() < mutation_rate:
            individual[i] = random.randint(0, 31)
    return individual

def selection(population, fitness_values):
    sorted_indices = np.argsort(fitness_values)[::-1]
    selected_population = []
    for i in sorted_indices:
        selected_population.append(population[i])
    return selected_population

def genetic_algorithm(pop_size, num_generations):
    population = generate_population(pop_size)

    for generation in range(num_generations):
        fitness_values = [fitness_function(x) for x in population]
        selected_population = selection(population, fitness_values)
        offspring = []

        for _ in range(pop_size // 2):
            parent1 = random.choice(selected_population)
            parent2 = random.choice(selected_population)
            child1, child2 = crossover(parent1, parent2)
            child1 = mutate(child1)
            child2 = mutate(child2)
            offspring.extend([child1, child2])

        population = offspring

    best_individual = max(population, key=fitness_function)
    return best_individual

if __name__ == "__main__":
    pop_size = 100
    num_generations = 100

    best_individual = genetic_algorithm(pop_size, num_generations)
    print("Best individual:", best_individual)
    print("Fitness value:", fitness_function(best_individual))

import random

# Define the range of x
x_min = 0
x_max = 31

# Define the probability of crossover and mutation
crossover_prob = 0.8
mutation_prob = 0.1

# Define the fitness function
def fitness_function(x):
    return x ** 2

# Initialize the population
def initialize_population(population_size):
    return [random.randint(x_min, x_max) for _ in range(population_size)]

# Select parents for crossover using tournament selection
def tournament_selection(population, fitness_scores):
    tournament_size = 2
    selected_parents = []
    for _ in range(len(population)):
        tournament = random.sample(list(enumerate(population)), tournament_size)
        selected_parents.append(max(tournament, key=lambda x: fitness_scores[x[0]])[1])
    return selected_parents

# Perform one-point crossover
def crossover(parent1, parent2):
    if random.random() < crossover_prob:
        crossover_point = random.randint(x_min, x_max)
        child1 = max(x_min, min(x_max, parent1 + parent2 - crossover_point))
        child2 = max(x_min, min(x_max, parent1 + parent2 - crossover_point))
        return child1, child2
    else:
        return parent1, parent2

# Perform mutation
def mutation(child):
    if random.random() < mutation_prob:
        mutation_value = random.randint(-1, 1)
        child = max(x_min, min(x_max, child + mutation_value))
    return child

# Genetic Algorithm
def genetic_algorithm(population_size, num_generations):
    population = initialize_population(population_size)
    fitness_scores = [fitness_function(x) for x in population]

    for generation in range(num_generations):
        # Select parents
        selected_parents = tournament_selection(population, fitness_scores)

        # Perform crossover and mutation
        offspring = []
        for i in range(0, len(selected_parents), 2):
            parent1 = selected_parents[i]
            parent2 = selected_parents[i + 1]
            child1, child2 = crossover(parent1, parent2)
            child1 = mutation(child1)
            child2 = mutation(child2)
            offspring.extend([child1, child2])

        # Replace the old population with offspring
        population = offspring
        fitness_scores = [fitness_function(x) for x in population]

    best_individual = max(population, key=fitness_function)
    return best_individual

# Set population size and number of generations
pop_size = 100
num_generations = 100

# Run the genetic algorithm
best_individual = genetic_algorithm(pop_size, num_generations)
print("Best individual:", best_individual)
print("Fitness value:", fitness_function(best_individual))

